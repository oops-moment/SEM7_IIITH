{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:25:42.228469Z","iopub.status.busy":"2024-09-11T06:25:42.227645Z","iopub.status.idle":"2024-09-11T06:25:55.238664Z","shell.execute_reply":"2024-09-11T06:25:55.237430Z","shell.execute_reply.started":"2024-09-11T06:25:42.228426Z"},"id":"4qG4ykyH5di6","outputId":"5cddf17e-6768-4c58-b285-018d484b6e6b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["#@title Import Required Libraries\n","import re\n","from gensim.models import KeyedVectors\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset , Dataset\n","import random\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from torch.nn.utils.rnn import pad_sequence , pack_padded_sequence, pad_packed_sequence\n","\n","\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:25:55.241842Z","iopub.status.busy":"2024-09-11T06:25:55.241113Z","iopub.status.idle":"2024-09-11T06:25:55.295097Z","shell.execute_reply":"2024-09-11T06:25:55.293832Z","shell.execute_reply.started":"2024-09-11T06:25:55.241792Z"},"id":"tIKNtT2q5di7","outputId":"31231585-a387-4ba8-da61-0a4ed54d0b1a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:25:55.297372Z","iopub.status.busy":"2024-09-11T06:25:55.296476Z","iopub.status.idle":"2024-09-11T06:26:07.420804Z","shell.execute_reply":"2024-09-11T06:26:07.419771Z","shell.execute_reply.started":"2024-09-11T06:25:55.297325Z"},"id":"wIFHa5i65di7","trusted":true},"outputs":[],"source":["def preprocess_text(text):\n","    \"\"\"\n","    Preprocess the text by:\n","    - Tokenizing sentences\n","    - Removing special characters and digits\n","    - Converting to lowercase\n","    \"\"\"\n","    sentences = sent_tokenize(text)\n","    cleaned_sentences = []\n","    for sentence in sentences:\n","        sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n","        sentence = sentence.lower()\n","        words = word_tokenize(sentence)\n","        if words:\n","            cleaned_sentences.append(words)\n","\n","    return cleaned_sentences\n","\n","def load_data(file_path):\n","    \"\"\"\n","    Loads text from a file and returns the cleaned sentences.\n","    \"\"\"\n","    with open(file_path, 'r') as f:\n","        text = f.read()  # Read the entire text\n","    return preprocess_text(text)\n","\n","# Load and preprocess the data\n","file_path = '/kaggle/input/training/Auguste_Maquet.txt'\n","sentences = load_data(file_path)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:07.423333Z","iopub.status.busy":"2024-09-11T06:26:07.423013Z","iopub.status.idle":"2024-09-11T06:26:07.428648Z","shell.execute_reply":"2024-09-11T06:26:07.427694Z","shell.execute_reply.started":"2024-09-11T06:26:07.423300Z"},"id":"njQXbcIu5di8","trusted":true},"outputs":[],"source":["def build_vocab(sentences, glove_dictionary):\n","    vocab = {'<UNK>': 0 ,'<PAD>':1}\n","    for sent in sentences:\n","        for word in sent:\n","            if word in glove_dictionary:\n","                if word not in vocab:\n","                    vocab[word] = len(vocab)\n","    return vocab"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:07.430009Z","iopub.status.busy":"2024-09-11T06:26:07.429745Z","iopub.status.idle":"2024-09-11T06:26:46.057668Z","shell.execute_reply":"2024-09-11T06:26:46.056683Z","shell.execute_reply.started":"2024-09-11T06:26:07.429980Z"},"id":"dZqdc-3K5di8","trusted":true},"outputs":[],"source":["glove_dict = {}\n","with open('/kaggle/input/gloves/glove.6B.300d.txt', encoding='utf-8') as file:\n","    for line in file:\n","        values = line.split()\n","        word = values[0]\n","        word_embedding = [float(x) for x in values[1:]]\n","        glove_dict[word] = word_embedding"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.059226Z","iopub.status.busy":"2024-09-11T06:26:46.058909Z","iopub.status.idle":"2024-09-11T06:26:46.098524Z","shell.execute_reply":"2024-09-11T06:26:46.097618Z","shell.execute_reply.started":"2024-09-11T06:26:46.059194Z"},"id":"r4GKSyqd5di9","outputId":"1d14d3df-ecde-4891-c278-a358b47fa7db","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train sentences: 24785\n","Test sentences: 7082\n","Validation sentences: 3541\n"]}],"source":["random.shuffle(sentences)\n","train_split = int(0.7 * len(sentences))\n","test_split = int(0.9 * len(sentences))\n","\n","train_sentences = sentences[:train_split]\n","test_sentences = sentences[train_split:test_split]\n","val_sentences = sentences[test_split:]\n","\n","print(f\"Train sentences: {len(train_sentences)}\")\n","print(f\"Test sentences: {len(test_sentences)}\")\n","print(f\"Validation sentences: {len(val_sentences)}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.100024Z","iopub.status.busy":"2024-09-11T06:26:46.099754Z","iopub.status.idle":"2024-09-11T06:26:46.251613Z","shell.execute_reply":"2024-09-11T06:26:46.250659Z","shell.execute_reply.started":"2024-09-11T06:26:46.099995Z"},"id":"ONbLxcN-5di9","trusted":true},"outputs":[],"source":["vocab = build_vocab(train_sentences, glove_dict)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.253057Z","iopub.status.busy":"2024-09-11T06:26:46.252755Z","iopub.status.idle":"2024-09-11T06:26:46.261736Z","shell.execute_reply":"2024-09-11T06:26:46.260833Z","shell.execute_reply.started":"2024-09-11T06:26:46.253025Z"},"id":"jjRAN8y05di-","outputId":"7bd0bed0-ef35-44cd-b474-ea527c3fa575","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The word with index 204 is 'guarantees'\n"]}],"source":["index_to_word = {index: word for word, index in vocab.items()}\n","index = 204\n","word = index_to_word.get(index, '<UNK>')\n","print(f\"The word with index {index} is '{word}'\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.263295Z","iopub.status.busy":"2024-09-11T06:26:46.263000Z","iopub.status.idle":"2024-09-11T06:26:46.278340Z","shell.execute_reply":"2024-09-11T06:26:46.277666Z","shell.execute_reply.started":"2024-09-11T06:26:46.263264Z"},"id":"LksWcl1v5di-","trusted":true},"outputs":[],"source":["embedding_matrix = [glove_dict[word] if word in glove_dict else [0]*300 for word in vocab]\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.282350Z","iopub.status.busy":"2024-09-11T06:26:46.281715Z","iopub.status.idle":"2024-09-11T06:26:46.834883Z","shell.execute_reply":"2024-09-11T06:26:46.834088Z","shell.execute_reply.started":"2024-09-11T06:26:46.282317Z"},"id":"tFv2sUHP5di-","trusted":true},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, sentences, vocab, embedding_matrix):\n","        self.sentences = sentences\n","        self.vocab = vocab\n","        self.embedding_matrix = embedding_matrix\n","\n","        # Filter out empty sequences and sequences with zero length\n","        self.data = self.create_sequences()\n","\n","    def create_sequences(self):\n","        sequences = []\n","        for sent in self.sentences:\n","            if len(sent) > 1:  # Ensure the sentence has more than one word\n","                input_seq = [self.vocab.get(word, self.vocab['<UNK>']) for word in sent[:-1]]\n","                output_seq = [self.vocab.get(word, self.vocab['<UNK>']) for word in sent[1:]]\n","                if len(input_seq) > 0 and len(output_seq) > 0:  # Check if sequences are non-empty\n","                    sequences.append((input_seq, output_seq))\n","        return sequences\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input_seq, output_seq = self.data[idx]\n","        input_embeds = torch.tensor(input_seq, dtype=torch.long)\n","        output_seq = torch.tensor(output_seq, dtype=torch.long)\n","        return input_embeds, output_seq\n","\n","train_dataset = TextDataset(train_sentences, vocab, embedding_matrix)\n","val_dataset = TextDataset(val_sentences, vocab, embedding_matrix)\n","test_dataset = TextDataset(test_sentences, vocab, embedding_matrix)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.836310Z","iopub.status.busy":"2024-09-11T06:26:46.836004Z","iopub.status.idle":"2024-09-11T06:26:46.875878Z","shell.execute_reply":"2024-09-11T06:26:46.875027Z","shell.execute_reply.started":"2024-09-11T06:26:46.836278Z"},"id":"BB6-X8Ey5di-","outputId":"ff75a994-1f27-471d-8727-73879aa20dc3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["24273\n","<class 'tuple'>\n","(tensor([21, 22, 23,  3, 24, 13, 25, 26, 11, 27]), tensor([22, 23,  3, 24, 13, 25, 26, 11, 27, 28]))\n"]}],"source":["print(len(train_dataset))\n","print(type(train_dataset[0]))\n","print(train_dataset[1])\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.877811Z","iopub.status.busy":"2024-09-11T06:26:46.877182Z","iopub.status.idle":"2024-09-11T06:26:46.885282Z","shell.execute_reply":"2024-09-11T06:26:46.884441Z","shell.execute_reply.started":"2024-09-11T06:26:46.877765Z"},"id":"F1vRI31f5di-","trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    batch.sort(key=lambda x: len(x[0]), reverse=True)\n","    sequences, targets = zip(*batch)\n","    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=vocab['<PAD>'])\n","    targets_padded = pad_sequence(targets, batch_first=True, padding_value=vocab['<PAD>'])\n","    lengths = [len(seq) for seq in sequences]\n","    return sequences_padded, targets_padded,torch.tensor(lengths)\n","BATCH_SIZE=64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:26:46.886600Z","iopub.status.busy":"2024-09-11T06:26:46.886294Z","iopub.status.idle":"2024-09-11T06:26:46.900152Z","shell.execute_reply":"2024-09-11T06:26:46.899287Z","shell.execute_reply.started":"2024-09-11T06:26:46.886569Z"},"id":"IpBLAxeU5di-","trusted":true},"outputs":[],"source":["import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self, embedding_matrix, hidden_dim, num_layers=2, dropout=0.5):\n","        super(LSTMModel, self).__init__()\n","\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)\n","\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n","                            dropout=dropout, batch_first=True)\n","\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","\n","    def forward(self, input_seq, lengths, hidden_state=None):\n","        # Embed the input sequence\n","        embedded = self.dropout(self.embedding(input_seq))\n","\n","        packed_input = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n","\n","        if hidden_state is None:\n","            h_0 = torch.zeros(self.num_layers, input_seq.size(0), self.hidden_dim).to(input_seq.device)\n","            c_0 = torch.zeros(self.num_layers, input_seq.size(0), self.hidden_dim).to(input_seq.device)\n","            hidden_state = (h_0, c_0)\n","\n","        packed_output, hidden_state = self.lstm(packed_input, hidden_state)\n","        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n","        output = self.fc(lstm_out)\n","        return output, hidden_state\n","\n","    def init_hidden(self, batch_size, device):\n","        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        return h_0, c_0"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:29:26.535586Z","iopub.status.busy":"2024-09-11T06:29:26.534848Z","iopub.status.idle":"2024-09-11T06:29:26.629499Z","shell.execute_reply":"2024-09-11T06:29:26.628612Z","shell.execute_reply.started":"2024-09-11T06:29:26.535545Z"},"id":"wAAJcAXp5di-","trusted":true},"outputs":[],"source":["embedding_matrix=np.array(embedding_matrix)\n","model = LSTMModel(embedding_matrix, hidden_dim=300, num_layers=2, dropout=0.5).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:29:27.844705Z","iopub.status.busy":"2024-09-11T06:29:27.843856Z","iopub.status.idle":"2024-09-11T06:29:27.856814Z","shell.execute_reply":"2024-09-11T06:29:27.855906Z","shell.execute_reply.started":"2024-09-11T06:29:27.844655Z"},"id":"QNQN0V6c5di-","trusted":true},"outputs":[],"source":["def train_model(model, train_loader, val_loader, num_epochs=10, patience=3):\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n","    vocab_size = len(vocab)\n","\n","    best_val_loss = float('inf')\n","    epochs_no_improve = 0\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0\n","\n","        for input_seq, target_seq, lengths in train_loader:\n","            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n","\n","            # Initialize hidden state at the start of each batch\n","            hidden = model.init_hidden(input_seq.size(0), device)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            output, hidden = model(input_seq, lengths, hidden)\n","\n","            # Reshape output and target for the loss calculation\n","            loss = loss_fn(output.view(-1, vocab_size), target_seq.view(-1))\n","\n","            # Backpropagation and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for input_seq, target_seq, lengths in val_loader:\n","                input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n","\n","                # No need to pass hidden state between batches during evaluation\n","                output, _ = model(input_seq, lengths)\n","\n","                # Calculate validation loss\n","                loss = loss_fn(output.view(-1, vocab_size), target_seq.view(-1))\n","                val_loss += loss.item()\n","\n","        # Calculate average validation loss\n","        val_loss /= len(val_loader)\n","        print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}\")\n","\n","        # Early stopping logic\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), 'best_model.pth')\n","            print(f\"Model saved with validation loss: {best_val_loss:.4f}\")\n","        else:\n","            epochs_no_improve += 1\n","            if epochs_no_improve >= patience:\n","                print(\"Early stopping!\")\n","                break"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:29:28.807433Z","iopub.status.busy":"2024-09-11T06:29:28.806587Z","iopub.status.idle":"2024-09-11T06:36:40.909081Z","shell.execute_reply":"2024-09-11T06:36:40.908036Z","shell.execute_reply.started":"2024-09-11T06:29:28.807392Z"},"id":"y35bSz5w5di_","outputId":"d792c4c7-8eba-4206-db0e-b4dab29c46da","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 6.741740704837598\n","Epoch 1, Validation Loss: 6.4021\n","Model saved with validation loss: 6.4021\n","Epoch 2, Loss: 6.367736385997973\n","Epoch 2, Validation Loss: 6.0732\n","Model saved with validation loss: 6.0732\n","Epoch 3, Loss: 6.100526918862995\n","Epoch 3, Validation Loss: 5.8513\n","Model saved with validation loss: 5.8513\n","Epoch 4, Loss: 5.899937745144492\n","Epoch 4, Validation Loss: 5.6865\n","Model saved with validation loss: 5.6865\n","Epoch 5, Loss: 5.7370334248793755\n","Epoch 5, Validation Loss: 5.5412\n","Model saved with validation loss: 5.5412\n","Epoch 6, Loss: 5.596185021651419\n","Epoch 6, Validation Loss: 5.4194\n","Model saved with validation loss: 5.4194\n","Epoch 7, Loss: 5.475631191855983\n","Epoch 7, Validation Loss: 5.3262\n","Model saved with validation loss: 5.3262\n","Epoch 8, Loss: 5.376115893062792\n","Epoch 8, Validation Loss: 5.2557\n","Model saved with validation loss: 5.2557\n","Epoch 9, Loss: 5.288211617971721\n","Epoch 9, Validation Loss: 5.1999\n","Model saved with validation loss: 5.1999\n","Epoch 10, Loss: 5.210024907714442\n","Epoch 10, Validation Loss: 5.1551\n","Model saved with validation loss: 5.1551\n"]}],"source":["train_model(model, train_loader, val_loader, num_epochs=10, patience=3)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:36:40.912114Z","iopub.status.busy":"2024-09-11T06:36:40.911232Z","iopub.status.idle":"2024-09-11T06:36:40.941828Z","shell.execute_reply":"2024-09-11T06:36:40.940865Z","shell.execute_reply.started":"2024-09-11T06:36:40.912063Z"},"id":"ogCSVFlP5di_","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_36/1559688700.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_model.pth'))\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('best_model.pth'))"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:40:03.171089Z","iopub.status.busy":"2024-09-11T06:40:03.169857Z","iopub.status.idle":"2024-09-11T06:40:03.179079Z","shell.execute_reply":"2024-09-11T06:40:03.178093Z","shell.execute_reply.started":"2024-09-11T06:40:03.171022Z"},"id":"foUDx2Th5di_","trusted":true},"outputs":[],"source":["def calculate_perplexity(model, data_loader, vocab, device):\n","    \"\"\"\n","    Calculate the perplexity of the model on the provided data_loader.\n","\n","    Args:\n","        model (nn.Module): The trained LSTM model.\n","        data_loader (DataLoader): DataLoader for the dataset (test or validation).\n","        vocab (dict): Vocabulary dictionary mapping words to indices.\n","        device (torch.device): The device to run the computations on.\n","\n","    Returns:\n","        float: The calculated perplexity.\n","    \"\"\"\n","    model.eval()\n","    data_loss = 0\n","    vocab_size=len(vocab)\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n","\n","    with torch.no_grad():\n","        for input_seq, target_seq, lengths in data_loader:\n","            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n","\n","            # No need to pass hidden state between batches during evaluation\n","            output, _ = model(input_seq, lengths)\n","\n","            # Calculate validation loss\n","            loss = loss_fn(output.view(-1, vocab_size), target_seq.view(-1))\n","            data_loss += loss.item()\n","\n","    # Calculate average validation loss\n","    data_loss /= len(data_loader)\n","    perplexity=torch.exp(torch.tensor(data_loss))\n","    return perplexity,data_loss\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:40:05.212225Z","iopub.status.busy":"2024-09-11T06:40:05.211190Z","iopub.status.idle":"2024-09-11T06:40:23.582234Z","shell.execute_reply":"2024-09-11T06:40:23.581176Z","shell.execute_reply.started":"2024-09-11T06:40:05.212183Z"},"id":"wZi5aqiZ5di_","outputId":"4a8a533c-6be7-429f-a90d-289f5ca0f8c3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Perplexity: 167.2379\n","Test Loss: 5.1194\n","Validation Perplexity: 162.6948\n","Validation Loss: 5.0919\n","Train Perplexity: 113.0193\n","Train Loss: 4.7276\n"]}],"source":["# Assuming you have a trained model, test_loader, vocab, and device\n","test_perplexity,test_loss = calculate_perplexity(model, test_loader, vocab, device)\n","print(f\"Test Perplexity: {test_perplexity:.4f}\")\n","print(f\"Test Loss: {test_loss:.4f}\")\n","\n","validation_perplexity,validation_loss = calculate_perplexity(model, val_loader, vocab, device)\n","print(f\"Validation Perplexity: {validation_perplexity:.4f}\")\n","print(f\"Validation Loss: {validation_loss :.4f}\")\n","\n","train_perplexity,train_loss = calculate_perplexity(model, train_loader, vocab, device)\n","print(f\"Train Perplexity: {train_perplexity:.4f}\")\n","print(f\"Train Loss: {train_loss :.4f}\")"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:41:15.814420Z","iopub.status.busy":"2024-09-11T06:41:15.814026Z","iopub.status.idle":"2024-09-11T06:41:15.825235Z","shell.execute_reply":"2024-09-11T06:41:15.824142Z","shell.execute_reply.started":"2024-09-11T06:41:15.814379Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def calculate_perplexity_and_save(model, data_loader, vocab, device, file_name):\n","    \"\"\"\n","    Calculate the perplexity of the model on the provided data_loader and save it to a file.\n","\n","    Args:\n","        model (nn.Module): The trained LSTM model.\n","        data_loader (DataLoader): DataLoader for the dataset (test or validation).\n","        vocab (dict): Vocabulary dictionary mapping words to indices.\n","        device (torch.device): The device to run the computations on.\n","        file_name (str): The file name to save the batch perplexities.\n","    \"\"\"\n","    model.eval()\n","    data_loss = 0\n","    vocab_size = len(vocab)\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n","    batch_losses = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (input_seq, target_seq, lengths) in enumerate(data_loader):\n","            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n","\n","            # No need to pass hidden state between batches during evaluation\n","            output, _ = model(input_seq, lengths)\n","\n","            # Calculate loss for each batch\n","            loss = loss_fn(output.view(-1, vocab_size), target_seq.view(-1))\n","            batch_loss = loss.item()\n","            batch_losses.append(batch_loss)\n","\n","            # Save cumulative loss for average calculation\n","            data_loss += batch_loss\n","\n","            # Calculate perplexity for the batch\n","            batch_perplexity = torch.exp(torch.tensor(batch_loss)).item()\n","\n","            # Save the perplexity score for this batch to the file\n","            with open(file_name, 'a') as f:\n","                f.write(f'Batch-{batch_idx + 1}\\t{batch_perplexity}\\n')\n","\n","    # Calculate the average loss and perplexity\n","    avg_loss = data_loss / len(data_loader)\n","    avg_perplexity = torch.exp(torch.tensor(avg_loss)).item()\n","\n","    # Append the average perplexity to the file\n","    with open(file_name, 'a') as f:\n","        f.write(f'Average\\t{avg_perplexity}\\n')\n","\n","    return avg_perplexity, avg_loss\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:41:17.368704Z","iopub.status.busy":"2024-09-11T06:41:17.368268Z","iopub.status.idle":"2024-09-11T06:41:17.374377Z","shell.execute_reply":"2024-09-11T06:41:17.373221Z","shell.execute_reply.started":"2024-09-11T06:41:17.368658Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE_FILE=1\n","train_loader_file = DataLoader(train_dataset, batch_size=BATCH_SIZE_FILE, shuffle=True, collate_fn=collate_fn)\n","val_loader_file = DataLoader(val_dataset, batch_size=BATCH_SIZE_FILE, shuffle=False, collate_fn=collate_fn)\n","test_loader_file = DataLoader(test_dataset, batch_size=BATCH_SIZE_FILE, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T06:41:19.786326Z","iopub.status.busy":"2024-09-11T06:41:19.785491Z","iopub.status.idle":"2024-09-11T06:41:38.200973Z","shell.execute_reply":"2024-09-11T06:41:38.199960Z","shell.execute_reply.started":"2024-09-11T06:41:19.786286Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(162.69479370117188, 5.091875908591531)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["calculate_perplexity_and_save(model, train_loader_file, vocab, device, '2021101075-LM2-train-perplexity.txt')\n","calculate_perplexity_and_save(model, test_loader_file, vocab, device, '2021101075-LM2-test-perplexity.txt')\n","calculate_perplexity_and_save(model, val_loader_file, vocab, device, '2021101075-LM2-val-perplexity.txt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5661058,"sourceId":9341166,"sourceType":"datasetVersion"},{"datasetId":5661064,"sourceId":9341178,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":117553,"modelInstanceId":93343,"sourceId":111401,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
